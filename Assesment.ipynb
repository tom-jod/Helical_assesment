{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-u0NcJw-3cL",
        "outputId": "8a157803-89c2-4d50-a3c0-de8fccd298ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "est\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install helical\n",
        "\n",
        "!pip install datasets --upgrade\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import anndata as ad\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch import nn\n",
        "from scipy.sparse import lil_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "ds = load_dataset(\"helical-ai/yolksac_human\",trust_remote_code=True, split=\"train[:65%]\",download_mode=\"reuse_cache_if_exists\")"
      ],
      "metadata": {
        "id": "EYTTEllt_FEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "observation_columns = [obs for obs in list(ds.features.keys()) if not obs == 'raw_counts']\n",
        "obs_data = pd.DataFrame(ds.select_columns(observation_columns).data.to_pandas(),columns=observation_columns)\n",
        "lil = lil_matrix((len(ds),ds[0]['size']))\n",
        "lil.data = np.array(ds['raw_counts'],dtype=\"object\")\n",
        "lil.rows = np.array(ds['rows'],dtype=\"object\")\n",
        "adata = ad.AnnData(lil.tocsr(),obs=obs_data)\n",
        "adata.var_names = ds.features['raw_counts'].id.split(\",\")\n",
        "adata.var['gene_name'] = adata.var_names.str.upper()"
      ],
      "metadata": {
        "id": "wzr3ALxB_MLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get labels: the celltype\n",
        "num_types = adata.obs[\"LVL1\"].unique().shape[0]\n",
        "id2type = dict(enumerate(adata.obs[\"LVL1\"].astype(\"category\").cat.categories))\n",
        "\n",
        "celltypes_labels = np.array(adata.obs[\"LVL1\"].tolist())"
      ],
      "metadata": {
        "id": "nNatQohJ_P5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "scgpt_config = scGPTConfig(batch_size=50, device=device)\n",
        "scgpt = scGPT(configurer = scgpt_config)\n",
        "print(adata.var.index)\n",
        "\n",
        "\n",
        "def knockout_genes(data,model,genes):\n",
        "  \"\"\" Generate embeddings for the original dataset and modified dataset using\n",
        "  the selected model. The modified dataset has gene expressions set to 0 for\n",
        "  all genes present in the genes list.\n",
        "\n",
        "  Inputs:\n",
        "      data (anndata): dataset that is being considered\n",
        "      model ()\n",
        "  \"\"\"\n",
        "  # knockout genes using batching to reduce explosion in RAM usage\n",
        "  batch_size = 200\n",
        "  x_model_dropped_list = []\n",
        "  for i in range(0, len(genes), batch_size):\n",
        "        batch_genes = genes[i:i+batch_size]\n",
        "        # set expression values for genes in the current batch to 0\n",
        "        for gene in batch_genes:\n",
        "            if gene in data.var.index:\n",
        "                gene_idx = list(data.var.index).index(gene)\n",
        "                data.X[:, gene_idx] = 0\n",
        "\n",
        "        # generate embeddings for the current batch of knockouts\n",
        "        new_data = model.process_data(adata=data, gene_names=\"gene_name\")\n",
        "        x_model_dropped = model.get_embeddings(new_data)\n",
        "        x_model_dropped_list.append(x_model_dropped)\n",
        "  # generate embeddings on original data\n",
        "  new_data = model.process_data(adata = data, gene_names = \"gene_name\")\n",
        "  x_model = model.get_embeddings(new_data)\n",
        "  print(x_model, x_model_dropped)\n",
        "  return x_model, x_model_dropped\n",
        "#genes_to_knockout = ['A1BG', 'A1BG-AS1', 'A1CF', 'A2M']\n",
        "genes_to_knockout = list(adata.var_names[0:int(len(adata.var_names)/2)])\n",
        "\n",
        "x_model, x_model_dropped = knockout_genes(adata,scgpt,genes_to_knockout)\n"
      ],
      "metadata": {
        "id": "qHpnJ_eI_QZS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}